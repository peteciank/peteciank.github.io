[
  {
    "objectID": "publications/publications.html",
    "href": "publications/publications.html",
    "title": "Publications",
    "section": "",
    "text": "For the latest publications see Google Scholar"
  },
  {
    "objectID": "publications/publications.html#papers",
    "href": "publications/publications.html#papers",
    "title": "Publications",
    "section": "Papers",
    "text": "Papers\n\n\n\n\n\n\n\n  \n    \n      A Scalable Framework for Closed-Loop Neuromodulation with Deep Learning \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2023. Nigel Gebodh, Vladimir Miskovic, Sarah Laszlo, Abhishek Datta, Marom Bikson. BioRxiv.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n      \n      \n      \n      \n         \n           Preprint \n         \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n         \n           GitHub \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Novel Evoked Synaptic Activity Potentials (ESAPs) Elicited by Spinal Cord Stimulation \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2023. Mahima Sharma, Vividha Bhaskar, Lillian Yang, Mohamad FallahRad, Nigel Gebodh, Tianhe Zhang, Rosana Esteller, John Martin, Marom Bikson. eNeuro.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n         \n           Open Access\n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Dataset of concurrent EEG, ECG, and behavior with multiple doses of transcranial electrical stimulation \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2021. Nigel Gebodh, Zeinab Esmaeilpour, Abhishek Datta, Marom Bikson. Nature Scientific Data.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n         \n           Open Access\n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n         \n           OSF\n        \n      \n\n      \n         \n           Zenodo\n        \n      \n\n      \n         \n           figshare\n        \n      \n      \n      \n         \n           GitHub \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Electrical stimulation of cranial nerves in cognition and disease \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2020. Devin Adair, Dennis Truong, Zeinab Esmaeilpour, Nigel Gebodh, Helen Borges, Libby Ho, Douglas J. Bremmer, Bashar W. Badran, Vitaly Napadow, Vincent P. Clark, Marom Bikson. Brain Stimulation.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n         \n           Open Access\n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Experimental-design Specific Changes in Spontaneous EEG and During Intermittent Photic Stimulation by High Definition Transcranial Direct Current Stimulation \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2020. Vladimir Lazarev, Nigel Gebodh, Tiago Tamborino, Marom Bikson, Egas M Caparelli-Daquer. Neuroscience.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n         \n           Open Access\n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Antiepileptic Effects of a Novel Non-invasive Neuromodulation Treatment in a Subject With Early-Onset Epileptic Encephalopathy: Case Report With 20 Sessions of HD-tDCS Intervention \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2019. Oded Meiron, Rena Gale, Julia Namestnic, Odeya Bennet-Back, Nigel Gebodh, Zeinab Esmaeilpour, Vladislav Mandzhiyev, Marom Bikson. Frontiers in Neuroscience.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n         \n           Open Access\n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Inherent physiological artifacts in EEG during tDCS \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2018. Nigel Gebodh, Zeinab Esmaeilpour, Devin Adair, Kenneth Chelette, Jacek Dmochowski, Adam J. Woods, Emily S. Kappenman, Lucas C. Parra, Marom Bikson. NeuroImage.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n      \n      \n         \n           Publisher's Version \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Effects of stimulus size and contrast on the initial primary visual cortical response in humans \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2017. Nigel Gebodh, Marta Isabel Vanegas, Simon P. Kelly. Brain Topogr.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n      \n      \n         \n           Publisher's Version \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Clinically Effective Treatment of Fibromyalgia Pain With High-Definition Transcranial Direct Current Stimulation: Phase II Open-Label Dose Optimization \n      \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n        \n          2015. Nigel Gebodh, Laura Castillo-Saavedra, Marom Bikson, Camilo Diaz-Cruz, Rivail Brandao, Livia Coutinho, Dennis Truong, Abhishek Datta, Revital Shani-Hershkovich, Michal Weiss, Ilan Laufer, Amit Reches, Ziv Peremen, Amir Geva, Lucas C. Parra, Felipe Fregni. J. Pain.\n        \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n         \n           Open Access\n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/publications.html#book-chapters",
    "href": "publications/publications.html#book-chapters",
    "title": "Publications",
    "section": "Book Chapters",
    "text": "Book Chapters\n\n\n\n\n\n\n\n  \n    \n      Transcranial direct current stimulation among technologies for low-intensity transcranial electrical stimulation: classification, history, and terminology \n      \n      \n\n      \n      \n        \n          Jan 24, 2019. Nigel Gebodh, Zeinab Esmaeilpour, Devin Adair, Pedro Schestattsky, Felipe Fregni, Marom Bikson. Chapter 1. Practical guide to transcranial direct current stimulation. \n        \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n      \n      \n         \n           Publisher's Version \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Transcranial direct current stimulation integration with magnetic resonance imaging, magnetic resonance spectroscopy, near infrared spectroscopy imaging, and electroencephalography \n      \n      \n\n      \n      \n        \n          Jan 24, 2019. Adam J. Woods, Marom Bikson, Kenneth Chelette, Jacek Dmochowski, Anirban Dutta, Zeinab Esmaeilpour, Nigel Gebodh, Michael A. Nitsche, Charlotte Stagg. Chapter 11. Practical guide to transcranial direct current stimulation. \n        \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n      \n      \n         \n           Publisher's Version \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Transcranial Electrical Stimulation: transcranial Direct Current Stimulation (tDCS), transcranial Alternating Current Stimulation (tACS), transcranial Pulsed Current Stimulation (tPCS), and Transcranial Random Noise Stimulaiton (tRNS) \n      \n      \n\n      \n      \n        \n          Jul 11, 2014. Ingrid Moreno-Duarte, Nigel Gebodh, Pedro Schestatsky, Berkan Guleyupoglu, Davide Reato, Marom Bikson, Felipe Fregni. Chapter 2. The Stimulated Brain. \n        \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n         \n           PDF \n         \n      \n      \n      \n      \n      \n         \n           Publisher's Version \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n\n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/publications.html#research-presentations",
    "href": "publications/publications.html#research-presentations",
    "title": "Publications",
    "section": "Research Presentations",
    "text": "Research Presentations\n\nGebodh N, Datta A, Bikson M. A Machine Learning Framework of Closed-loop Neuromodulation Applied to Sustained Attentional Enhancement. Poster session presented at Military Health System Research Symposium; 2022 Sep 12- 15; Kissimmee, FL.\nGebodh N, Miskovic V, Laszlo S, Datta A, Bikson M. Deep learning framework for non-invasive closed-loop neuromodulation for attention. Poster session presented at Neuroergonomics & NYC Neuromodulation; 2022 Jul 28- Aug 1; New York, NY.\nSharma M, Bhaskar V, Yang L, Gebodh N, FallahRad M, Zhang T, Esteller R, Martin J, Bikson M. Evoked Synaptic Excitatory Potentials (ESAPs): A novel electrophysiological biomarker for Spinal Cord Stimulation. Poster session presented at Neuroergonomics & NYC Neuromodulation; 2022 Jul 28- Aug 1; New York, NY.\nGebodh N, Bikson M. A Machine Learning Based Closed-Loop Neuromodulation Framework. Poster session presented at The International Neuromodulation Society; 2022 May 21-26; Barcelona, Spain. Doi: https://doi.org/10.1016/j.neurom.2022.08.002\nGebodh N, Esmaeilpour Z, Datta A, Bikson M. A novel approach to closed-loop neuromodulation with machine learning. Poster session presented at 4th International Brain Stimulation Conference; 2021 Dec 7-10;Charleston,South Carolina. Doi: https://doi.org/10.1016/j.brs.2021.10.235\nGebodh N, Esmaeilpour Z, Datta A, Bikson M. A large open source neuromodulation dataset of concurrent EEG, ECG, behavior, and transcranial electrical stimulation. Poster session presented at 4th International Brain Stimulation Conference; 2021 Dec 7-10;Charleston,South Carolina. Doi: https://doi.org/10.1016/j.brs.2021.10.108\nGebodh N, Vacchi L, Adair D, Esmaeilpour Z, Poltorak A, Poltorak V, Bikson M. Modulation of Sleepiness and Physiology with Brain-Derived and Narrow-Band tACS. Poster session presented at 2019 Neuromodulation: The Science and NYC Neuromodulation Joint Meeting; 2019 Oct 2-5; Napa, California.\nVacchi L, Gebodh N, Adair D, Unal G, Poltorak A, Poltorak V, Bikson M. Transcranial Endogenous Sleep-Derived waveform to induce sleepiness. Poster session presented at The Annual Meeting of Milan Center for Neuroscience; 2018 Nov 21; Milan, Italy.\nGebodh N, Adair D, Esmaeilpour Z, Chelette K, Dmochowski J, Woods A, Kappenman E, Bikson M. Failure of Conventional Signal Processing Techniques to Remove “Physiological” Artifacts from EEG During tDCS. Poster session presented at 2018 NYC Neuromodulation Conference and NANS Summer Series; 2018 Aug 24-26; New York, NY.\nMeiron O, Gale R, Namestnic J, Bennet-Back O, David J, Gebodh N, Adair D, Esmaeilpour Z, Bikson M. Attenuation of pathological EEG features in nonatal electroclinical syndromes: HD-tDCS in catastrophic epilepsies. Poster session presented at Brain Stimulation: Basic, Translational, and Clinical Research in Neuromodulation; 2018 Aug 24-26; New York, NY.\nGebodh N, Vacchi L, Adair D, Unal G, Poltorak A, Poltorak V, Bikson M. Replay of endogenous sleep rhythms to produce sleepiness. Poster session presented at 2018 NYC Neuromodulation Conference and NANS Summer Series; 2018 Aug 24-26; New York, NY. Doi: https://doi.org/10.1016/j.brs.2018.12.180\nGebodh N, Adair D, Esmaeilpour Z, Chelette K, Dmochowski J, Woods A, Kappenman E, Bikson M. Physiologic artifacts when combining EEG and tDCS. Poster session presented at 2nd International Brain Stimulation Conference; 2017 Mar 5-8; Barcelona, Spain.\nGebodh N, Adair D, Esmaeilpour Z, Chelette K, Dmochowski J, Woods A, Kappenman E, Bikson M. Modulation of physiologic artifacts during concurrent tDCS and EEG. Poster session presented at 6th International Conference on Transcranial Brain Stimulation; 2016 Sept 7-10; Gottingen, DE.\nGebodh N, Castillo L, Truong D, Bikson M, Shani-Hershkovich R, Weiss M, Laufer I, Reches A, Peremen Z, Geva A, Parra LC, and Fregni F. Clinically effective treatment of fibromyalgia pain with HD-tDCS – Phase II open-label dose-optimization. Poster session presented at Military Health Research Systems Symposium; 2015 Aug. 16-21; Ft. Lauderdale, FL.\nGebodh N, Vanegas I, Kelly S. Characterization of the effects of stimulus size and contrast on the initial afferent response in human primary visual cortex. Poster session presented at Society for Neuroscience; 2014 Nov. 15-19; Washington DC.\nVanegas I, Blangero A, Gebodh N, Ali A, Kelly S. Task-dependent attentional modulation of initial afferent activity in human primary visual cortex. Poster session presented at Society for Neuroscience; 2014 Nov. 15-19; Washington DC."
  },
  {
    "objectID": "publications/publications.html#ad-hoc-review",
    "href": "publications/publications.html#ad-hoc-review",
    "title": "Publications",
    "section": "Ad Hoc Review",
    "text": "Ad Hoc Review\n\nBrain Stimulation\n\nSleep Medicine\n\nPLOS Comp Bio\n\nJ.NeuroEng & Rehab\nNeuroImage\nNeuropsychologia\nApplied Intelligence\nPsychophysiology\nHemodialysis Intl"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nigel Gebodh, PhD",
    "section": "",
    "text": "I currently work on building, understanding, and integrating machine learning/artificial intelligent systems.\nI’m interested in the intersection of machine learning, intelligent agents, digital health, wearables, signal processing, and understanding brain and body connections.\nI completed my PhD work in Neural and Biomedical Engineering with fellowships awarded from the NIH and Grove School of Engineering."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Nigel Gebodh, PhD",
    "section": "",
    "text": "I currently work on building, understanding, and integrating machine learning/artificial intelligent systems.\nI’m interested in the intersection of machine learning, intelligent agents, digital health, wearables, signal processing, and understanding brain and body connections.\nI completed my PhD work in Neural and Biomedical Engineering with fellowships awarded from the NIH and Grove School of Engineering."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Nigel Gebodh, PhD",
    "section": "Experience",
    "text": "Experience\n\nMeta - Reality Labs\nPhilips - Healthcare\nSoterix Medical Inc./ Google X (Collaboration)\nHarvard Medical School - Spaulding Rehab Hospital"
  },
  {
    "objectID": "index.html#select-publications",
    "href": "index.html#select-publications",
    "title": "Nigel Gebodh, PhD",
    "section": "Select Publications",
    "text": "Select Publications\n\nA Scalable Framework for Closed-Loop Neuromodulation with Deep Learning. Nigel Gebodh, Vladimir Miskovic, Sarah Laszlo, Abhishek Datta, Marom Bikson. bioRxiv 2023.01.18.524615; doi: https://doi.org/10.1101/2023.01.18.524615\nDataset of concurrent EEG, ECG, and behavior with multiple doses of transcranial electrical stimulation. Nigel Gebodh, Zeinab Esmaeilpour, Abhishek Datta, Marom Bikson. Nature Sci Data 8, 274 (2021); doi: https://doi.org/10.1038/s41597-021-01046-y\nInherent physiological artifacts in EEG during tDCS. Nigel Gebodh, Zeinab Esmaeilpour, Devin Adair, Kenneth Chelette, Jacek Dmochowski, Adam J Woods, Emily S Kappenman, Lucas C Parra, Marom Bikson. Neuroimage 185, (2019/1/15); doi: https://doi.org/10.1016/j.neuroimage.2018.10.025\n\n\nSee all publications here."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Nigel Gebodh, PhD",
    "section": "Education",
    "text": "Education\nThe Grove School of Engineering,  The City College of New York, CUNY  NIH-GRISE and Grove School of Engineering Fellow\n\nPhD & MPhil\nBuilding improved wearables, and assessing neural (sleep/attention/vigilance) and physiological function (EEG, ECG, EMG etc.) under brain stimulation with computational modeling, and machine learning.\n\n\nMSci\nUnderstanding the human visual system by mapping the early visual cortex. Applying machine learning, signal detection, and signal processing techniques.\n\n\nBE\nMedical device design, device manufacturing, and rapid prototyping."
  },
  {
    "objectID": "media/media.html",
    "href": "media/media.html",
    "title": "Talks & Media",
    "section": "",
    "text": "NYC Neuromodulation & Neuroergonomics Conference 2022, Deep learning framework for non-invasive closed-loop neuromodulation for attention, Invited Talk, New York NY, Jul. 2022\nNeuroergonomics Conference 2021,Introduction to practical methods in low-intensity transcranial Electrical Stimulation, Workshop, Virtual, Sep. 2021\nNYC Neuromodulation 2020, M/EEG with noninvasive brain stimulation (NIBS): Artifacts, Modeling, and Removal, Invited Talk, Virtual, Apr. 2020\nNeuromodulation: The Science, Applying HD-tES: A Practical Guide, Workshop, Napa CA, Oct. 2019\nANT neuro, Live application of tDCS/EEG: common problems and solutions, Invited Talk, EEG-tDCS & EEG-TMS methodology in research and clinical research settings, New York NY Jul. 2017\n\nThe City College of New York, Electrophysiology: theory, practical application, and artifacts, Invited Talk, Biomedical Instrumentation, New York NY, Mar. 2017\nNYC Neuromodulation 2017, A practical guide to combining HD-tDCS and EEG, Invited Talk, New York NY, Jan. 2017\nAdvanced Science Research Center, CUNY, Outdoor EEG and Concurrent Environmental Monitoring, Invited Talk, New York NY, Oct. 2016\nThe City College of New York, Biostatistics and research methods, Graduate Teaching, New York NY, 2015\nThe City College of New York, An Introduction to MATLAB and Data Visualization, Graduate Teaching, New York NY, 2015\nChegg, Math for Engineers, Data Analysis, and Programming, Tutoring, Virtual, 2013\nThe City College of New York, A practical guide to 3D printing, Zahn Center NYC, Invited Talk, New York NY, Jun. 2013"
  },
  {
    "objectID": "media/media.html#talks-teaching",
    "href": "media/media.html#talks-teaching",
    "title": "Talks & Media",
    "section": "",
    "text": "NYC Neuromodulation & Neuroergonomics Conference 2022, Deep learning framework for non-invasive closed-loop neuromodulation for attention, Invited Talk, New York NY, Jul. 2022\nNeuroergonomics Conference 2021,Introduction to practical methods in low-intensity transcranial Electrical Stimulation, Workshop, Virtual, Sep. 2021\nNYC Neuromodulation 2020, M/EEG with noninvasive brain stimulation (NIBS): Artifacts, Modeling, and Removal, Invited Talk, Virtual, Apr. 2020\nNeuromodulation: The Science, Applying HD-tES: A Practical Guide, Workshop, Napa CA, Oct. 2019\nANT neuro, Live application of tDCS/EEG: common problems and solutions, Invited Talk, EEG-tDCS & EEG-TMS methodology in research and clinical research settings, New York NY Jul. 2017\n\nThe City College of New York, Electrophysiology: theory, practical application, and artifacts, Invited Talk, Biomedical Instrumentation, New York NY, Mar. 2017\nNYC Neuromodulation 2017, A practical guide to combining HD-tDCS and EEG, Invited Talk, New York NY, Jan. 2017\nAdvanced Science Research Center, CUNY, Outdoor EEG and Concurrent Environmental Monitoring, Invited Talk, New York NY, Oct. 2016\nThe City College of New York, Biostatistics and research methods, Graduate Teaching, New York NY, 2015\nThe City College of New York, An Introduction to MATLAB and Data Visualization, Graduate Teaching, New York NY, 2015\nChegg, Math for Engineers, Data Analysis, and Programming, Tutoring, Virtual, 2013\nThe City College of New York, A practical guide to 3D printing, Zahn Center NYC, Invited Talk, New York NY, Jun. 2013"
  },
  {
    "objectID": "media/media.html#media",
    "href": "media/media.html#media",
    "title": "Talks & Media",
    "section": "Media",
    "text": "Media\n\nNIH G-RISE Research Highlight, CCNY Division of Science, 2023\nTechnology Feature in Quartz: The Objects that Power the Global Economy, pg. 64-65. 2017\nHBO Vice News, March 30, 2017\nGrove School of Engineering, City College of New York - Access to Excellence, 2014\nM/EEG with noninvasive brain stimulation (NIBS): Artifacts, Modeling, and Removal,NYC Neuromodulation, 2020\nNeuromodec’s Top Impactful Neuromodulation articles of 2021, Neuromodec, 2021"
  },
  {
    "objectID": "projects/2024-03-05/index.html",
    "href": "projects/2024-03-05/index.html",
    "title": "Large Language Models - Chatting with AI Chatbots from Google, Mistral AI, and Hugging Face",
    "section": "",
    "text": "Show me the demo!\n  LLMs\n  \n  LLMs what are they good for?\n  LLMs how do they work?\n  What is Gemma?\n  What is Mistral?\n  What is Zephyr?\n  \n  Setting Up Models with Hugging Face and Streamlit\n  What’s Next"
  },
  {
    "objectID": "projects/2024-03-05/index.html#show-me-the-demo",
    "href": "projects/2024-03-05/index.html#show-me-the-demo",
    "title": "Large Language Models - Chatting with AI Chatbots from Google, Mistral AI, and Hugging Face",
    "section": "Show me the demo!",
    "text": "Show me the demo!\nJump straight to the chatbot demo"
  },
  {
    "objectID": "projects/2024-03-05/index.html#llms",
    "href": "projects/2024-03-05/index.html#llms",
    "title": "Large Language Models - Chatting with AI Chatbots from Google, Mistral AI, and Hugging Face",
    "section": "LLMs",
    "text": "LLMs\nLarge language models (LLMs) have become widespread and accessible. Hugging Face has helped accelerate the accessibility and use of these models by aggregating them in one place and creating helpful APIs1 to use them.\n1 API - Application programming interfaceHere, we’ll use Streamlit to look at some of the state-of-the-art LLMs on Hugging Face that can be easily set-up for quick inference in a chatbot interface:\n\nMistral 7B\nGemma 7B and 2B\nZephyr 7B-β\n\n\nLLMs what are they good for?\nLarge language models (LLMs) are powerful AI systems that can generate natural language texts based on a given input. They’ve been used for a number of tasks in the field of natural language processing (NLP)2. These have included text summarization, translation, sentiment analysis (e.g. tell you if your text has a positive or negative sentiment), etc.\n2 NLP -Natural Language Processing3 These are AI models that you can prompt with questionsOne of the most exciting applications of LLMs has been the creation of interactive question and answer chatbots3. These have been used to augment writing, have conversations, help generate code, and more! If you’ve tried OpenAI’s ChatGPT then you know how powerful a tool LLMs can be.\n\n\nLLMs how do they work?\nLLMs work through a number of different complex steps (greatly oversimplified):\n\nWords are first converted into high dimensional numeric vectors, representing their semantic meanings. Think of techniques like Word2Vec or GloVe4. These vectors embed different dimensions of meaning that correspond to each word5.\nThese vectors are fed into a massive machine learning model (typically a Transformer architecture) that learns patterns, probabilities, and relationships between words.\nThis training enables the model to generate coherent and contextually relevant text, based on new input it receives.\n\n4 GloVe - Global Vectors for Word Representation5 Jay Alammar does a great job explaining it here.\n\nWhat is Gemma?\n\nGemma is described as a family of lightweight models. It was developed by DeepMind and other teams at Google. These models were used to create Google’s Gemini models. The name of the model comes from the Latin word gemma, translating to ‘gem’ or precious stone.\nThe open source Gemma model is based on the transformer decoder architecture and comes in two sizes: a 7B and 2B. These represent the number of parameters that each model has, which are actually 7,751,248,896 (7B) and 1,981,884,416 (2B). On benchmarks the Gemma model performs on par or better than the LLaMA and Mistral models. You can check out the interactive benchmark comparisons here.\nOne thing to note is that the current 7B Hugging Face implementation of the Gemma model may have some hiccups, which are being looked into by the Hugging Face team6 so use it with caution.\n6 Jeremy Howard’s take\n\nWhat is Mistral?\n\nMistral was created by the Paris-based Mistral AI team. The founders of the team came from Meta Platforms and Google’s DeepMind. Similar to the Gemma model the Mistral model (specifically the Mistral-7B model) is based on the transformer architecture and has about 7 billion parameters. The name Mistral presumably comes from the term describing strong, cold, winds that blow through France from south to the Mediterranean.\n\n\nWhat is Zephyr?\n\nThe Zephyr models are a series of models that were fine-tuned by the team at Hugging Face. The Zephyr 7B-β model is the second of (currently) 3 models and is a fine-tuned version of the Mistral 7B model. The idea behind model fine-tuning is to improve the accuracy of the models. In this case the Mistral model was additionally fine-tuned with AI feedback (AIF). Similar to the term mistral the word zephyr refers to a soft, gentle breeze.\nOne of the latest Zephyr models, Zephyr 7B Gemma is a fine-tuned version of the Gemma model by Google, however it has not yet been configured for inference on Hugging Face. There is an interactive demo available though, check it out here."
  },
  {
    "objectID": "projects/2024-03-05/index.html#setting-up-models-with-hugging-face-and-streamlit",
    "href": "projects/2024-03-05/index.html#setting-up-models-with-hugging-face-and-streamlit",
    "title": "Large Language Models - Chatting with AI Chatbots from Google, Mistral AI, and Hugging Face",
    "section": "Setting Up Models with Hugging Face and Streamlit",
    "text": "Setting Up Models with Hugging Face and Streamlit\nHugging Face hosts a number of open-source, pre-trained LLMs and allows you to directly interface with them through API calls. When getting started we’ll first need an API key7, which is free after creating a Hugging Face account.\n7 It will be an alpha numeric code starting with hf\nWe first install all the libraries we’ll be using. We’ll use the OpenAI API to stream model output from but other APIs exist.\n!pip install openai python-dotenv\nNext we assign the client interface that’ll be helping us with API calls to HuggingFace. If you’re using Hugging Face spaces be sure to add your Hugging Face API key to your secret codes in your space settings.\nimport streamlit as st\nfrom openai import OpenAI\nimport os\nimport sys\nfrom dotenv import load_dotenv, dotenv_values\n\n#This loads env variables like your API keys\nload_dotenv() \nWe create a dictionary with the model names and their URLs.\n#Create supported models\nmodel_links ={\n              \"Mistral\":\"mistralai/Mistral-7B-Instruct-v0.2\",\n              \"Gemma-7B\":\"google/gemma-7b-it\",\n              \"Gemma-2B\":\"google/gemma-2b-it\",\n              \"Zephyr-7B-β\":\"HuggingFaceH4/zephyr-7b-beta\",\n              }\nWe’ll also create a dictionary with some info about the models.\n#Pull info about the model to display\nmodel_info ={\n    \"Mistral\":\n        {'description':\n            \"\"\"The Mistral model is a **Large Language Model (LLM)** that's able to have question and answer interactions...\"\"\",\n        'logo':\n            'https://mistral.ai/images/logo_hubc88c4ece131b91c7cb753f40e9e1cc5_2589_256x0_resize_q97_h2_lanczos_3.webp'},\n    \"Gemma-7B\":        \n        {'description':\n            \"\"\"The Gemma model is a **Large Language Model (LLM)** that's able to have question and answer interactions...\"\"\",\n        'logo':\n            'https://pbs.twimg.com/media/GG3sJg7X0AEaNIq.jpg'},\n    \"Gemma-2B\":        \n        {'description':\n            \"\"\"The Gemma model is a **Large Language Model (LLM)** that's able to have question and answer interactions...\"\"\",\n        'logo':\n            'https://pbs.twimg.com/media/GG3sJg7X0AEaNIq.jpg'},\n    \"Zephyr-7B\":        \n        {'description':\n            \"\"\"The Zephyr model is a **Large Language Model (LLM)** that's able to have question and answer interactions...\"\"\",\n        'logo':\n            'https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-v0.1/resolve/main/thumbnail.png'},\n    \"Zephyr-7B-β\":        \n        {'description':\n            \"\"\"The Zephyr model is a **Large Language Model (LLM)** that's able to have question and answer interactions...\"\"\",\n        'logo':\n            'https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha/resolve/main/thumbnail.png'},  \n\n              }              \nCreate a function that wipes the session conversation if a button is pushed\ndef reset_conversation():\n    '''\n    Resets Conversation\n    '''\n    st.session_state.conversation = []\n    st.session_state.messages = []\n    return None\nWe configure the session settings in Streamlit and add some buttons.\n  # Define the available models\n  models =[key for key in model_links.keys()]\n\n  # Create the sidebar with the dropdown for model selection\n  selected_model = st.sidebar.selectbox(\"Select Model\", models)\n\n  #Create a temperature slider\n  temp_values = st.sidebar.slider('Select a temperature value', 0.0, 1.0, (0.5))\n\n\n  #Add reset button to clear conversation\n  st.sidebar.button('Reset Chat', on_click=reset_conversation) #Reset button\n\n\n  # Create model description\n  st.sidebar.write(f\"You're now chatting with **{selected_model}**\")\n  st.sidebar.markdown(model_info[selected_model]['description'])\n  st.sidebar.image(model_info[selected_model]['logo'])\n  st.sidebar.markdown(\"*Generated content may be inaccurate or false.*\")\n\n  st.subheader(f'AI - {selected_model}')\nWe do some configurations to clean up our messages and make sure we have the model selected.\n  #Keep track of which model we're using\n  if \"prev_option\" not in st.session_state:\n      st.session_state.prev_option = selected_model\n\n  #Clear conv if we change models\n  if st.session_state.prev_option != selected_model:\n      st.session_state.messages = []\n      st.session_state.prev_option = selected_model\n      reset_conversation()\n\n  #Pull in the model we want to use\n  repo_id = model_links[selected_model]\n\n  # Set a default model\n  if selected_model not in st.session_state:\n      st.session_state[selected_model] = model_links[selected_model] \n\n  # Initialize chat history\n  if \"messages\" not in st.session_state:\n      st.session_state.messages = []\n\n  # Display chat messages from history on app rerun\n  for message in st.session_state.messages:\n      with st.chat_message(message[\"role\"]):\n          st.markdown(message[\"content\"])\nFinally we set up the chat interface in Streamlit where the user’s questions or prompt gets passed on to the model we select and the model or the assistant returns a response. We make sure to keep adding our prompt and response to the messages structure we created so the model has some context to keep a conversation going.\n# Accept user input\nif prompt := st.chat_input(f\"Hi I'm {selected_model}, ask me a question\"):\n\n    # Display user message in chat message container\n    with st.chat_message(\"user\"):\n        st.markdown(prompt)\n    # Add user message to chat history\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n\n\n    # Display assistant response in chat message container\n    with st.chat_message(\"assistant\"):\n        stream = client.chat.completions.create(\n            model=model_links[selected_model],\n            messages=[\n                {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n                for m in st.session_state.messages\n            ],\n            temperature=temp_values,#0.5,\n            stream=True,\n            max_tokens=3000,\n        )\n\n        response = st.write_stream(stream)\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\nIf we’re running this locally we can use streamlit run app.py or on Hugging Face wait for all parts to build automatically. When everything’s up and running the interface will look like below. On the left panel the drop-down lets us switch between models and the temperature slider let’s us adjust the model’s temperature value.\n\n\n      \n      \n \nThe full script can be found here."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\nMar 20, 2024\n\n\nInteractive Neuromodulation Landscape\n\n\n6 min\n\n\n\n\nMar 5, 2024\n\n\nLarge Language Models - Chatting with AI Chatbots from Google, Mistral AI, and Hugging Face\n\n\n13 min\n\n\n\n\nMar 5, 2024\n\n\nDemo - LLM chatbot with models from Google, Mistral AI, and Hugging Face\n\n\n1 min\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "projects/2024-03-19/index.html",
    "href": "projects/2024-03-19/index.html",
    "title": "Interactive Neuromodulation Landscape",
    "section": "",
    "text": "Image by DALL-E 3"
  },
  {
    "objectID": "projects/2024-03-19/index_test.html",
    "href": "projects/2024-03-19/index_test.html",
    "title": "The Neuromodulation Landscape",
    "section": "",
    "text": "This is an interactive mapping of different types of neuromodulation or brain stimulation techniques.\nThis mapping is based on my book chapter.\n\n\n\nNeuromodulation is the action of interacting with or altering activity in the nervous system through the delivery of a stimulus. These stimuli can range from electrical currents, magnetic pulses, light, ultrasound, heat, etc. The terms neuromodulation and brain stimulation are often used interchangably, although in some cases differences exist.\nCheck out this deeper discussion on the difference.\n\n\n\n\nUse the navigation buttons at the top to change the layout of the chart.\nTo expand the chart categories click on the dropdown arrows.\nClick on the numbers within each block to create a root mapping.\nYou can export your selection with the buttons on top.\n\n\n\nThis is a work in progress and will be periodically updated. Email me with any feedback!"
  },
  {
    "objectID": "projects/2024-03-19/index_test.html#what-is-this",
    "href": "projects/2024-03-19/index_test.html#what-is-this",
    "title": "Interactive Neuromodulation Landscape",
    "section": "What is this?",
    "text": "What is this?\nThis is an interactive mapping of different types of neuromodulation or brain stimulation techniques.\nThis mapping is based on my book chapter."
  },
  {
    "objectID": "projects/2024-03-19/index_test.html#what-is-neuromodulation",
    "href": "projects/2024-03-19/index_test.html#what-is-neuromodulation",
    "title": "Interactive Neuromodulation Landscape",
    "section": "What is neuromodulation?",
    "text": "What is neuromodulation?\nNeuromodulation is the action of interacting with or altering activity in the nervous system through the delivery of a stimulus. These stimuli can range from electrical currents, magnetic pulses, light, ultrasound, heat, etc. The terms neuromodulation and brain stimulation are often used interchangably, although in some cases differences exist.\nCheck out this deeper discussion on the difference."
  },
  {
    "objectID": "projects/2024-03-19/index_test.html#footnotes",
    "href": "projects/2024-03-19/index_test.html#footnotes",
    "title": "The Neuromodulation Landscape",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCheck out this deeper discussion on the difference↩︎"
  },
  {
    "objectID": "projects/2024-03-19/index_test.html#how-do-i-use-this",
    "href": "projects/2024-03-19/index_test.html#how-do-i-use-this",
    "title": "Interactive Neuromodulation Landscape",
    "section": "How do I use this?",
    "text": "How do I use this?\n\nUse the navigation buttons at the top to change the layout of the chart.\nTo expand the chart categories click on the dropdown arrows.\nClick on the numbers on the upper right within each block to create a root mapping.\nUse the clear button to remove tree mapping.\nYou can drag the map around the fit your screen.\nYou can enter full screen mode.\nYou can export your selection with the buttons on top.\n\n\nFeedback\nThis is a work in progress and will be periodically updated. Email me with any feedback."
  },
  {
    "objectID": "projects/2024-03-19/index.html#what-is-this",
    "href": "projects/2024-03-19/index.html#what-is-this",
    "title": "Interactive Neuromodulation Landscape",
    "section": "What is this?",
    "text": "What is this?\nThis is an interactive mapping of different types of neuromodulation or brain stimulation techniques.\nThis mapping is based on my book chapter."
  },
  {
    "objectID": "projects/2024-03-19/index.html#what-is-neuromodulation",
    "href": "projects/2024-03-19/index.html#what-is-neuromodulation",
    "title": "Interactive Neuromodulation Landscape",
    "section": "What is neuromodulation?",
    "text": "What is neuromodulation?\nNeuromodulation is the action of interacting with or altering activity in the nervous system through the delivery of a stimulus. These stimuli can range from electrical currents, magnetic pulses, light, ultrasound, heat, etc. The terms neuromodulation and brain stimulation are often used interchangeably, although in some cases differences exist.\nCheck out this deeper discussion on the difference."
  },
  {
    "objectID": "projects/2024-03-19/index.html#how-do-i-use-this",
    "href": "projects/2024-03-19/index.html#how-do-i-use-this",
    "title": "Interactive Neuromodulation Landscape",
    "section": "How do I use this?",
    "text": "How do I use this?\n\nUse the navigation buttons at the top to change the layout of the chart.\nTo expand the chart categories click on the dropdown arrows.\nClick on the numbers on the upper right within each block to create a root mapping.\nUse the clear button to remove tree mapping.\nYou can drag the map around to fit your screen.\nYou can enter full screen mode.\nYou can export your selection with the buttons on top.\n\n\nFeedback\nThis is a work in progress and will be periodically updated. Email me with any feedback."
  }
]